{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data cleaning finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert anonymized data for further processing\n",
    "Input: anonymized data\n",
    "Output: filtered features matrix for modeling,\n",
    "        unfiltered features matrix for exploring\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import re\n",
    "\n",
    "\n",
    "# read in data\n",
    "df = pd.read_csv('../data/CYSOanonymized.csv')\n",
    "\n",
    "# set financial aid status to 0 if NaN\n",
    "\n",
    "df['finaid'].fillna(0,inplace=True)\n",
    "\n",
    "# parse race into different rows\n",
    "df['race'].fillna('Other',inplace=True)\n",
    "df['caucasian']=0\n",
    "df['african_american']=0\n",
    "df['native_american']=0\n",
    "df['latino']=0\n",
    "df['asian']=0\n",
    "df['other_race']=0\n",
    "df['race_num']=0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if re.search('cauc', str(row['race']), re.IGNORECASE):\n",
    "        df.loc[index,'caucasian']=1\n",
    "        df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "    if re.search('african', str(row['race']), re.IGNORECASE):\n",
    "        df.loc[index,'african_american']=1\n",
    "        df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "    if re.search('native', str(row['race']), re.IGNORECASE):\n",
    "        df.loc[index,'caucasian']=1\n",
    "        df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "    if re.search('latino', str(row['race']), re.IGNORECASE):\n",
    "        df.loc[index,'latino']=1\n",
    "        df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "    if re.search('asian', str(row['race']), re.IGNORECASE):\n",
    "        if not re.search('caucasian', str(row['race']), re.IGNORECASE):\n",
    "            df.loc[index,'asian']=1\n",
    "            df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "    if re.search('other', str(row['race']), re.IGNORECASE):\n",
    "        df.loc[index,'other_race']=1\n",
    "        df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "    if re.search(\"`\", str(row['race']), re.IGNORECASE):\n",
    "        df.loc[index,'other_race']=1\n",
    "        df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "\n",
    "# compile gender\n",
    "df['male']=0\n",
    "df['female']=0\n",
    "\n",
    "df.gender = df.gender.str.strip()\n",
    "df.gender.replace('Male','M',inplace=True)\n",
    "df.gender.replace('Female','F',inplace=True)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['gender']=='M':\n",
    "        df.loc[index, 'male']=1\n",
    "    if row['gender']=='F':\n",
    "        df.loc[index,'female']=1\n",
    "\n",
    "# compile major\n",
    "\n",
    "df['music']=0\n",
    "\n",
    "music_terms = ['performance','music','violin','songwriting','perfomance','bass','cello','viola','jazz']\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for music_term in music_terms:\n",
    "        if re.search(music_term,str(row['major']),re.IGNORECASE):\n",
    "            df.loc[index,'music']=1\n",
    "    \n",
    "\n",
    "'''\n",
    "map in and combine incomes\n",
    "'''\n",
    "#read in incomes and convert to numeric\n",
    "income = pd.read_csv('../data/income_zip.csv')\n",
    "df['homezip']=pd.to_numeric(df['homezip'], errors='coerce')\n",
    "\n",
    "# merge with data structure\n",
    "df = pd.merge(df,income,how='left',left_on='homezip',right_on='Zip')\n",
    "\n",
    "\n",
    "# rename and reformat columns\n",
    "df.rename(index=str, columns={\"Mean\": \"mean_income\", \"Median\": \"median_income\", \\\n",
    "                              \"finaid\" : \"financial_aid\", \"race_num\" : \"multiracial\"}, inplace=True)\n",
    "df['mean_income'] = df['median_income'].str.replace(',','')\n",
    "df['mean_income']=pd.to_numeric(df['mean_income'], errors='coerce')\n",
    "df['median_income'] = df['median_income'].str.replace(',','')\n",
    "df['median_income']=pd.to_numeric(df['median_income'], errors='coerce')\n",
    "df['income_diff']=df['mean_income']-df['median_income']\n",
    "\n",
    "'''\n",
    "map in and combine college data\n",
    "'''\n",
    "\n",
    "# read in college data\n",
    "uf = pd.read_csv('../data/colleges.csv')\n",
    "\n",
    "# filter to relevant universal columns\n",
    "uf = uf[['displayName','acceptance-rate','institutionalControl']]\n",
    "\n",
    "# build columns for merging and saving\n",
    "df['uni_close'] = 'none'\n",
    "df['uni_save'] = df['uni']\n",
    "\n",
    "# replace strings\n",
    "\n",
    "# strip name function\n",
    "def stripnames(dataframe,instring,outstring):\n",
    "    dataframe.loc[df['uni'].str.replace(' ','').replace(\"'\",'').replace('-','') \\\n",
    "                  ==instring.replace(' ','').replace(\"'\",'').replace('-',''),'uni']=outstring\n",
    "    return dataframe\n",
    "\n",
    "# strip and modify names for matching\n",
    "uf['displayName'] = uf['displayName'].fillna('none')\n",
    "df['uni'] = df['uni'].fillna('none given')\n",
    "df['uni'] = df['uni'].str.replace('Uof','University of')\n",
    "df['uni'] = df['uni'].str.replace('U of','University of')\n",
    "df['uni'] = df['uni'].str.replace('Jacobs School of Music','')\n",
    "df = stripnames(df,'Indiana University','Indiana University--Bloomington')\n",
    "df = stripnames(df,'NYU','New York University')\n",
    "df = stripnames(df,'Oberlin','Oberlin College')\n",
    "df = stripnames(df,'UIC','University of Illinois Chicago')\n",
    "df = stripnames(df,'UIUC','University of Illinois--Urbana Champaign')\n",
    "df = stripnames(df,'USC(So.Cal.)','University of Southern California')\n",
    "df = stripnames(df,'UofMichigan','University of Michigan')\n",
    "df = stripnames(df,'Peabody','Johns Hopkins University')\n",
    "df = stripnames(df,'University of I','University of Illinois--Urbana Champaign')\n",
    "df = stripnames(df,'NIU','Northern Illinois University')\n",
    "df = stripnames(df,'U.ofMinnesotaCarlsonSchoolofBusiness','University of Minnesota')\n",
    "df = stripnames(df,'NEC','New England Conservatory')\n",
    "df = stripnames(df,'MIT','Massachussetts Institute of Technology')\n",
    "df = stripnames(df,'Gap Year','none')\n",
    "df = stripnames(df,'Year off','none')\n",
    "df = stripnames(df,'The Juilliard School','Julliard School')\n",
    "df = stripnames(df,'IUBloomington,JacobsSchoolofMusic','Indiana University--Bloomington')\n",
    "df = stripnames(df,'IUJacobsSchoolofMusic','Indiana University--Bloomington')\n",
    "df = stripnames(df,'HarvardCollege','Harvard University')\n",
    "df = stripnames(df,'Undecided','none')\n",
    "df = stripnames(df,'NotgoingtoCollege','none')\n",
    "df = stripnames(df,'IndianaUniversityJacobsSchoolofMusic','Indiana University--Bloomington')\n",
    "df = stripnames(df,'IndianaUniversity,JacobsSchoolofMusic','Indiana University--Bloomington')\n",
    "df = stripnames(df,'IndianaUniversity(JacobsSchoolofMusic)','Indiana University--Bloomington')\n",
    "df = stripnames(df,'JacobsSchoolofMusic,atIndianaUniversity','Indiana University--Bloomington')\n",
    "df = stripnames(df,'ClarendonHillsMiddleSchool','none')\n",
    "df = stripnames(df,'IU','Indiana University--Bloomington')\n",
    "df = stripnames(df,'LawrenceConservatory','Lawrence University')\n",
    "df = stripnames(df,'IndianaUniversity','Indiana University--Bloomington')\n",
    "df = stripnames(df,'WesternIllinoisUniversity','WesternIllinois')\n",
    "df = stripnames(df,'UniversityofIllinois','University of Illinois--Urbana Champaign')\n",
    "df = stripnames(df,',atIndianaUniversity','Indiana University--Bloomington')\n",
    "\n",
    "# match name to closest\n",
    "for index, row in df.iterrows():\n",
    "    df.loc[index, 'uni_close']=process.extractOne(row['uni'],uf['displayName'])[0]\n",
    "\n",
    "\n",
    "# merge university data into full data structure\n",
    "df = pd.merge(df,uf,how='left',left_on='uni_close',right_on='displayName')\n",
    "\n",
    "# encode university types\n",
    "df['uni_public'] = 0\n",
    "# df.loc(df['institutionalControl']=='private','institutionalControl')=0\n",
    "# df.loc(df['institutionalControl']=='none','institutionalControl')=0\n",
    "df.loc[df['institutionalControl']=='public','uni_public']=1\n",
    "\n",
    "# drop spurious columns and rename others\n",
    "df.drop(['Unnamed: 0','Zip','institutionalControl','displayName','uni_save','uni'],axis=1, inplace=True)\n",
    "df.rename(index=str, columns={\"uni_close\": \"uni\",\"acceptance-rate\":\"acceptance_rate\"}, inplace=True)\n",
    "\n",
    "# force non numerics to numerics\n",
    "df['acceptance_rate']=pd.to_numeric(df['acceptance_rate'], errors='coerce')\n",
    "\n",
    "\"\"\"\n",
    "Use zip codes to determine if in city of chicago\n",
    "\"\"\"\n",
    "\n",
    "# read in city of chicago zipcodes\n",
    "zipcodes = pd.read_csv('../data/chicago_zipcodes.csv')\n",
    "\n",
    "# convert to integers\n",
    "df['s_zip']=pd.to_numeric(df['s_zip'], errors='coerce')\n",
    "df.s_zip = df.s_zip.fillna(0)\n",
    "df.s_zip = df.s_zip.astype(int)\n",
    "df['homezip']=pd.to_numeric(df['homezip'], errors='coerce')\n",
    "df.homezip = df.homezip.fillna(0)\n",
    "df.homezip = df.homezip.astype(int)\n",
    "zipcodes['ZIP']=pd.to_numeric(zipcodes['ZIP'], errors='coerce',downcast='integer')\n",
    "zipcodes.ZIP = zipcodes.ZIP.astype(int)\n",
    "df.loc[df['s_state'].isnull(),'s_zip'] = 60608\n",
    "\n",
    "# convert states to be consistent\n",
    "df.loc[df['s_state'].isnull(),'s_state'] = 'IL'\n",
    "df.loc[df['s_state']=='Illinois','s_state']='IL'\n",
    "df.loc[df['s_state']=='illinois','s_state']='IL'\n",
    "df.loc[df['s_state']=='il','s_state']='IL'\n",
    "df.loc[df['s_state']=='Il','s_state']='IL'\n",
    "df.loc[df['s_state']=='iL','s_state']='IL'\n",
    "df.loc[df['s_state']=='il.','s_state']='IL'\n",
    "df.loc[df['s_state']=='Il ','s_state']='IL'\n",
    "df.loc[df['s_state']=='Ilinois','s_state']='IL'\n",
    "df.loc[df['s_state']=='Illinoid','s_state']='IL'\n",
    "df.loc[df['s_state']=='Wisconsin','s_state']='WI'\n",
    "df.loc[df['s_state']=='Ill','s_state']='IL'\n",
    "\n",
    "# column for in chicago\n",
    "df['chi_school']=0\n",
    "df['notchi_school']=0\n",
    "df['chi_home']=0\n",
    "df['notchi_home']=0\n",
    "\n",
    "df.loc[df['s_zip'].isin(zipcodes['ZIP']),'chi_school']=1\n",
    "df.loc[~df['s_zip'].isin(zipcodes['ZIP']),'notchi_school']=1\n",
    "df.loc[df['homezip'].isin(zipcodes['ZIP']),'chi_home']=1\n",
    "df.loc[~df['homezip'].isin(zipcodes['ZIP']),'notchi_home']=1\n",
    "\n",
    "\"\"\"\n",
    "make seperate column for stratification?\n",
    "\"\"\"\n",
    "\n",
    "df['stratification_column'] = 0\n",
    "df.loc[df['african_american']==1,'stratification_column']=1\n",
    "df.loc[df['latino']==1,'stratification_column']=1\n",
    "\n",
    "\"\"\"\n",
    "add in public/private school status\n",
    "make columns for public/private\n",
    "make columns for chipub vs not chipub\n",
    "\"\"\"\n",
    "\n",
    "# read in data\n",
    "hs = pd.read_csv('../data/highschools.csv')\n",
    "\n",
    "#set up rows for matching\n",
    "df['hs_close'] = 'none'\n",
    "hs['school'] = hs['school'].fillna('none')\n",
    "df['school'] = df['school'].fillna('none')\n",
    "df['school'] = df['school'].str.replace(' ','').replace(\"'\",'').replace('-','')\n",
    "hs['school'] = hs['school'].str.replace(' ','').replace(\"'\",'').replace('-','')\n",
    "# match name to closest\n",
    "for index, row in df.iterrows():\n",
    "    df.loc[index, 'hs_close']=process.extractOne(row['school'],hs['school'])[0]\n",
    "    \n",
    "# merge data\n",
    "df = pd.merge(df,hs,how='left',left_on='hs_close',right_on='school')\n",
    "\n",
    "# make numeric column\n",
    "df['hs_public'] = 0\n",
    "df['hs_private'] = 0\n",
    "df.loc[df['pph']=='Public','hs_public']=1\n",
    "df.loc[df['pph']=='Private','hs_private']=1\n",
    "df['chipub'] = df['chi_school']*df['hs_public']\n",
    "df['subpub'] = df['notchi_school']*df['hs_public']\n",
    "\n",
    "# save full data structure\n",
    "df.to_csv('../data/exploring_data.csv')\n",
    "\n",
    "\n",
    "# for fitting data including likely correlated features\n",
    "df_fit = df[['female','other_race','notchi_school','notchi_home',\n",
    "             'subpub','hs_public','chipub','hs_private',\n",
    "             'uni_public','acceptance_rate','stratification_column',\n",
    "             'music','male','caucasian','african_american',\n",
    "             'latino', 'asian','chi_school','chi_home','financial_aid',\n",
    "             'median_income']]\n",
    "\n",
    "# for fitting data including likely correlated features\n",
    "df_fit_limited = df[['female','other_race','notchi_school','notchi_home',\n",
    "             'subpub','hs_public','chipub','hs_private',\n",
    "             'stratification_column',\n",
    "             'music','male','caucasian','african_american',\n",
    "             'latino', 'asian','chi_school','chi_home','financial_aid']]\n",
    "\n",
    "# # for logistic regression classifiers\n",
    "# df = df[['music','male','caucasian','african_american',\n",
    "#          'latino', 'asian','multiracial','financial_aid',\n",
    "#          'median_income','acceptance_rate','uni_public']]\n",
    "\n",
    "# save fitting data structure\n",
    "df_fit.to_csv('../data/fitting_data.csv')\n",
    "\n",
    "\"\"\"\n",
    "aggregate on county level data\n",
    "\"\"\"\n",
    "\n",
    "cf = pd.read_csv('../data/zip_county.txt')\n",
    "cf = cf[['ZCTA5','COUNTY','STATE']]\n",
    "df = pd.merge(df,cf,how='left',left_on='s_zip',right_on='ZCTA5')\n",
    "df.loc[df['COUNTY'].isnull(),'COUNTY'] = 31\n",
    "df.loc[df['STATE'].isnull(),'STATE'] = 17\n",
    "df['s_county'] = '17031'\n",
    "for index, row in df.iterrows():\n",
    "    if row['COUNTY']>=100:\n",
    "        df.loc[index,'s_county'] = str(int(row['STATE'])) + str(int(row['COUNTY']))\n",
    "    else:\n",
    "        df.loc[index,'s_county'] = str(int(row['STATE'])) + '0' + str(int(row['COUNTY']))\n",
    "df.loc[df['s_county']=='42095','s_county']='42077'\n",
    "\n",
    "# for mapping in tableau\n",
    "df_map = df[['female','male','music','caucasian','african_american',\n",
    "             'latino','asian','other_race','s_zip','s_state','s_county','financial_aid']]\n",
    "\n",
    "\n",
    "df_map.to_csv('../data/mapping_data_county.csv')\n",
    "\n",
    "# df_map_schools = df[['hs_private','hs_public']]\n",
    "\n",
    "# # save fitting data structure\n",
    "# df_map_schools.to_csv('../data/mapping_data_schools.csv')\n",
    "\n",
    "print('data cleaning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['s_county']=df['s_county'].str.replace('.0','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 50)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['s_state']=='Illinois','s_state']='IL'\n",
    "df.loc[df['s_state']=='illinois','s_state']='IL'\n",
    "df.loc[df['s_state']=='il','s_state']='IL'\n",
    "df.loc[df['s_state']=='Il','s_state']='IL'\n",
    "df.loc[df['s_state']=='iL','s_state']='IL'\n",
    "df.loc[df['s_state']=='il.','s_state']='IL'\n",
    "df.loc[df['s_state']=='Il ','s_state']='IL'\n",
    "df.loc[df['s_state']=='Ilinois','s_state']='IL'\n",
    "df.loc[df['s_state']=='Illinoid','s_state']='IL'\n",
    "df.loc[df['s_state']=='Wisconsin','s_state']='WI'\n",
    "df.loc[df['s_state']=='Ill','s_state']='IL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48     0\n",
       "61     0\n",
       "95     0\n",
       "358    0\n",
       "Name: s_zip, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['s_state'].isnull()].s_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.sample of 0      60423\n",
       "1      60423\n",
       "2      60002\n",
       "3      60068\n",
       "4      60532\n",
       "5      60502\n",
       "6      60502\n",
       "7      60521\n",
       "8      60521\n",
       "9      60069\n",
       "10     60441\n",
       "11     60544\n",
       "12     60544\n",
       "13     60525\n",
       "14     60089\n",
       "15     60089\n",
       "16     60608\n",
       "17     60506\n",
       "18     60435\n",
       "19     60067\n",
       "20     60194\n",
       "21     60521\n",
       "22     60521\n",
       "23     60487\n",
       "24     60487\n",
       "25     60015\n",
       "26     60015\n",
       "27     60004\n",
       "28     60106\n",
       "29     60077\n",
       "       ...  \n",
       "610    60607\n",
       "611    60605\n",
       "612    60077\n",
       "613    60610\n",
       "614    60174\n",
       "615    60174\n",
       "616    60101\n",
       "617    60137\n",
       "618    60564\n",
       "619    60564\n",
       "620    60060\n",
       "621    61364\n",
       "622    61364\n",
       "623    60030\n",
       "624    60126\n",
       "625    60126\n",
       "626    60067\n",
       "627    60438\n",
       "628    60451\n",
       "629    60126\n",
       "630    60126\n",
       "631    60540\n",
       "632    60637\n",
       "633    60521\n",
       "634    60521\n",
       "635    60506\n",
       "636    60093\n",
       "637    60077\n",
       "638    60069\n",
       "639    60077\n",
       "Name: s_zip, Length: 640, dtype: int64>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.s_zip.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.s_state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
