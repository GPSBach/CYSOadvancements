{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.color_palette(\"muted\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of variables to be excluded for logistic regression\n",
    "# these must be the first two variables in the feature matrix\n",
    "logit_num = 6\n",
    "\n",
    "# global inputs\n",
    "# names of models to be fitted in the loop\n",
    "model_names = ['l1','l2','rf','gb','linsvc','rbfsvc']\n",
    "\n",
    "'''\n",
    "Model Building\n",
    "'''\n",
    "\n",
    "# Pipeline dictionary\n",
    "pipelines = {\n",
    "    'l1' : make_pipeline(StandardScaler(), LogisticRegression( penalty = 'l1', random_state=125)),\n",
    "    'l2' : make_pipeline(StandardScaler(), LogisticRegression( penalty = 'l2', random_state=125)),\n",
    "    'rf' : make_pipeline(StandardScaler(), RandomForestClassifier(random_state=125)),\n",
    "    'gb' : make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=125)),\n",
    "    'linsvc' : make_pipeline(StandardScaler(), SVC(random_state=125,probability=True)),\n",
    "    'rbfsvc' : make_pipeline(StandardScaler(), SVC(random_state=125,probability=True))\n",
    "}\n",
    "\n",
    "# Logistic Regression hyperparameters\n",
    "l1_hyperparameters = {\n",
    "    'logisticregression__C' : np.linspace(1e-2, 1e1, 500)\n",
    "}\n",
    "\n",
    "l2_hyperparameters = {\n",
    "    'logisticregression__C' : np.linspace(1e-2, 1e1, 500)\n",
    "}\n",
    "\n",
    "# Random Forest hyperparameters\n",
    "rf_hyperparameters = {\n",
    "    'randomforestclassifier__n_estimators': [100, 300, 500],\n",
    "    'randomforestclassifier__max_features': ['auto', 'sqrt', 0.33],\n",
    "    'randomforestclassifier__max_depth': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Boosted Tree hyperparameters\n",
    "gb_hyperparameters = {\n",
    "    'gradientboostingclassifier__n_estimators': [100, 300, 500],\n",
    "    'gradientboostingclassifier__learning_rate': [0.01, 0.1, 0.5, 1],\n",
    "    'gradientboostingclassifier__max_depth': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "linsvc_hyperparameters = {\n",
    "    'svc__C' : [1e-5, 1e-3, 1e-1, 1e1],\n",
    "    'svc__kernel' : ['linear']\n",
    "}\n",
    "\n",
    "rbfsvc_hyperparameters = {\n",
    "    'svc__C': [1e-5, 1e-3, 1e-1, 1e1],\n",
    "    'svc__gamma' : [1e-5, 1e-3, 1e-1, 1e1],\n",
    "    'svc__kernel' : ['rbf']\n",
    "}\n",
    "# Create hyperparameters dictionary\n",
    "hyperparameters = {\n",
    "    'l1' : l1_hyperparameters, \n",
    "    'l2' : l2_hyperparameters,\n",
    "    'rf' : rf_hyperparameters,\n",
    "    'gb' : gb_hyperparameters,\n",
    "    'linsvc' : linsvc_hyperparameters,\n",
    "    'rbfsvc' : rbfsvc_hyperparameters\n",
    "}\n",
    "# Create data pointing dictionary\n",
    "datapointers = {\n",
    "    'l1' : 'logistic',\n",
    "    'l2' : 'logistic',\n",
    "    'rf' : 'not_logistic',\n",
    "    'gb' : 'not_logistic',\n",
    "    'linsvc' : 'not logistic',\n",
    "    'rbfsvc' : 'not logistic'\n",
    "}\n",
    "\n",
    "def model_scoring_auc(X_in, y_in, model, datapointer):\n",
    "    if datapointer == 'logistic':\n",
    "        pred = model.predict_proba(X_in[:,logit_num:])\n",
    "    else:\n",
    "        pred = model.predict_proba(X_in)\n",
    "    # Get just the prediction for the positive class (1)\n",
    "    pred = [p[1] for p in pred]\n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_in, pred)\n",
    "    # Calculate AUROC\n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "\n",
    "def model_fitting(X, y, logit_num, model_names, pipelines, hyperparameters, datapointers, randstate,stratcolumn):\n",
    "    # Create empty dictionary called fitted_models\n",
    "    fitted_models = {}\n",
    "    fitted_scores = {}\n",
    "    \n",
    "    # split data for CV testing\n",
    "    \n",
    "    #this works:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=randstate,stratify=stratcolumn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "    for name in model_names:\n",
    "        # Create cross-validation object from pipeline and hyperparameters\n",
    "        model = GridSearchCV(pipelines[name], hyperparameters[name], scoring = 'neg_log_loss', cv=10, refit=True)\n",
    "\n",
    "        # Fit model on X_train, y_train\n",
    "        if datapointers[name] == 'logistic':\n",
    "            model.fit(X_train[:,logit_num:], y_train)  \n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        # Store model in fitted_models[name] \n",
    "        fitted_models[name] = model\n",
    "        \n",
    "        # store scores in fitted_scores[name]\n",
    "        train_score = model_scoring_auc(X_train, y_train, model, datapointers[name])\n",
    "        test_score = model_scoring_auc(X_test, y_test, model, datapointers[name])\n",
    "        fitted_scores[name] = [train_score,test_score]\n",
    "            \n",
    "    return fitted_models, fitted_scores\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 model {'l1': [0.7415556842308435, 0.7351351351351351], 'l2': [0.7455767869780608, 0.7472972972972973], 'rf': [0.7976259409380428, 0.7258258258258258], 'gb': [0.7854178729974908, 0.7339339339339339], 'linsvc': [0.7181689506530272, 0.7430930930930931], 'rbfsvc': [0.8066332110918099, 0.6277777777777778]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../data/limited_data.csv')\n",
    "df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "df = df.fillna(0)\n",
    "y = df.pop('music').values\n",
    "stratification_columns = df.pop('stratification_column').values\n",
    "X = df.values\n",
    "\n",
    "\n",
    "models_iterate = {}\n",
    "scores_iterate = {}\n",
    "for i in range(1):\n",
    "    models_iterate[i], scores_iterate[i] = model_fitting(X,y,logit_num,model_names,pipelines,hyperparameters,datapointers,i+12000,stratification_columns)\n",
    "    if i%10 == 0:\n",
    "        print('step',i,'model',scores_iterate[i])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('../data/all_limit_models.pkl', 'wb') as picklefile:\n",
    "    pkl.dump(models_iterate, picklefile)\n",
    "with open('../data/all_limit_models_scores.pkl', 'wb') as picklefile:\n",
    "    pkl.dump(scores_iterate, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
