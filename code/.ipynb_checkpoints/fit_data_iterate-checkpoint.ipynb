{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.color_palette(\"muted\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of variables to be excluded for logistic regression\n",
    "# these must be the first two variables in the feature matrix\n",
    "\n",
    "# global inputs\n",
    "logit_num = 6\n",
    "model_names = ['l2']\n",
    "\n",
    "'''\n",
    "Model Building\n",
    "'''\n",
    "\n",
    "# Pipeline dictionary\n",
    "pipelines = {\n",
    "    'l1' : make_pipeline(StandardScaler(), LogisticRegression( penalty = 'l1', random_state=125)),\n",
    "    'l2' : make_pipeline(StandardScaler(), LogisticRegression( penalty = 'l2', random_state=125)),\n",
    "    'rf' : make_pipeline(StandardScaler(), RandomForestClassifier(random_state=125)),\n",
    "    'gb' : make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=125)),\n",
    "    'linsvc' : make_pipeline(StandardScaler(), SVC(random_state=125,probability=True)),\n",
    "    'rbfsvc' : make_pipeline(StandardScaler(), SVC(random_state=125,probability=True))\n",
    "}\n",
    "\n",
    "# Logistic Regression hyperparameters\n",
    "l1_hyperparameters = {\n",
    "    'logisticregression__C' : np.linspace(1e-2, 1e1, 500)\n",
    "}\n",
    "\n",
    "l2_hyperparameters = {\n",
    "    'logisticregression__C' : np.linspace(1e-2, 1e1, 500)\n",
    "}\n",
    "\n",
    "# Random Forest hyperparameters\n",
    "rf_hyperparameters = {\n",
    "    'randomforestclassifier__n_estimators': [100, 300, 500],\n",
    "    'randomforestclassifier__max_features': ['auto', 'sqrt', 0.33],\n",
    "    'randomforestclassifier__max_depth': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Boosted Tree hyperparameters\n",
    "gb_hyperparameters = {\n",
    "    'gradientboostingclassifier__n_estimators': [100, 300, 500],\n",
    "    'gradientboostingclassifier__learning_rate': [0.01, 0.1, 0.5, 1],\n",
    "    'gradientboostingclassifier__max_depth': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "linsvc_hyperparameters = {\n",
    "    'svc__C' : [1e-5, 1e-3, 1e-1, 1e1],\n",
    "    'svc__kernel' : ['linear']\n",
    "}\n",
    "\n",
    "rbfsvc_hyperparameters = {\n",
    "    'svc__C': [1e-5, 1e-3, 1e-1, 1e1],\n",
    "    'svc__gamma' : [1e-5, 1e-3, 1e-1, 1e1],\n",
    "    'svc__kernel' : ['rbf']\n",
    "}\n",
    "# Create hyperparameters dictionary\n",
    "hyperparameters = {\n",
    "    'l1' : l1_hyperparameters, \n",
    "    'l2' : l2_hyperparameters,\n",
    "    'rf' : rf_hyperparameters,\n",
    "    'gb' : gb_hyperparameters,\n",
    "    'linsvc' : linsvc_hyperparameters,\n",
    "    'rbfsvc' : rbfsvc_hyperparameters\n",
    "}\n",
    "# Create data pointing dictionary\n",
    "datapointers = {\n",
    "    'l1' : 'logistic',\n",
    "    'l2' : 'logistic',\n",
    "    'rf' : 'not_logistic',\n",
    "    'gb' : 'not_logistic',\n",
    "    'linsvc' : 'not logistic',\n",
    "    'rbfsvc' : 'not logistic'\n",
    "}\n",
    "\n",
    "def model_scoring_auc(X_in, y_in, model, datapointer):\n",
    "    if datapointer == 'logistic':\n",
    "        pred = model.predict_proba(X_in[:,logit_num:])\n",
    "    else:\n",
    "        pred = model.predict_proba(X_in)\n",
    "    # Get just the prediction for the positive class (1)\n",
    "    pred = [p[1] for p in pred]\n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_in, pred)\n",
    "    # Calculate AUROC\n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "\n",
    "def model_fitting(X, y, logit_num, model_names, pipelines, hyperparameters, datapointers, randstate,stratcolumn):\n",
    "    # Create empty dictionary called fitted_models\n",
    "    fitted_models = {}\n",
    "    fitted_scores = {}\n",
    "    \n",
    "    # split data for CV testing\n",
    "    \n",
    "    #this works:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=randstate,stratify=stratcolumn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "    for name in model_names:\n",
    "        # Create cross-validation object from pipeline and hyperparameters\n",
    "        model = GridSearchCV(pipelines[name], hyperparameters[name], scoring = 'neg_log_loss', cv=10, refit=True)\n",
    "\n",
    "        # Fit model on X_train, y_train\n",
    "        if datapointers[name] == 'logistic':\n",
    "            model.fit(X_train[:,logit_num:], y_train)  \n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        # Store model in fitted_models[name] \n",
    "        fitted_models[name] = model\n",
    "        \n",
    "        # store scores in fitted_scores[name]\n",
    "        train_score = model_scoring_auc(X_train, y_train, model, datapointers[name])\n",
    "        test_score = model_scoring_auc(X_test, y_test, model, datapointers[name])\n",
    "        fitted_scores[name] = [train_score,test_score]\n",
    "            \n",
    "    return fitted_models, fitted_scores\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 model {'l2': [0.7877501125908769, 0.7927927927927928]}\n",
      "step 10 model {'l2': [0.7647604426533616, 0.8680379746835443]}\n",
      "step 20 model {'l2': [0.7855702119485177, 0.7648530331457161]}\n",
      "step 30 model {'l2': [0.7713283989092327, 0.8292964244521338]}\n",
      "step 40 model {'l2': [0.7951104411089991, 0.7346938775510204]}\n",
      "step 50 model {'l2': [0.7972320146233189, 0.7548433048433049]}\n",
      "step 60 model {'l2': [0.8161529940705023, 0.7046883933676387]}\n",
      "step 70 model {'l2': [0.7863516299445948, 0.7861822513400833]}\n",
      "step 80 model {'l2': [0.8065347956652305, 0.7062678062678063]}\n",
      "step 90 model {'l2': [0.8067280592514912, 0.7015306122448979]}\n",
      "step 100 model {'l2': [0.781647005444646, 0.7684057971014493]}\n",
      "step 110 model {'l2': [0.7563741668284476, 0.8206997084548106]}\n",
      "step 120 model {'l2': [0.7851114547094447, 0.7902025014889816]}\n",
      "step 130 model {'l2': [0.8130695674496213, 0.6961444308445532]}\n",
      "step 140 model {'l2': [0.7868860415453309, 0.7596209912536444]}\n",
      "step 150 model {'l2': [0.7956774193548386, 0.7452718676122932]}\n",
      "step 160 model {'l2': [0.796882126800026, 0.7492853058890795]}\n",
      "step 170 model {'l2': [0.7736038309713323, 0.8081632653061225]}\n",
      "step 180 model {'l2': [0.8011803213648085, 0.7124293785310735]}\n",
      "step 190 model {'l2': [0.802512514439738, 0.7132802937576499]}\n",
      "step 200 model {'l2': [0.784163288940359, 0.7711711711711713]}\n",
      "step 210 model {'l2': [0.7965206435355688, 0.7573356807511736]}\n",
      "step 220 model {'l2': [0.7640606880556631, 0.837403216200119]}\n",
      "step 230 model {'l2': [0.7841189455914817, 0.7902249134948097]}\n",
      "step 240 model {'l2': [0.8061138211382113, 0.723163030998852]}\n",
      "step 250 model {'l2': [0.7683135960654889, 0.8355685131195335]}\n",
      "step 260 model {'l2': [0.7989926739926739, 0.7369318181818182]}\n",
      "step 270 model {'l2': [0.7929268292682926, 0.7379448909299656]}\n",
      "step 280 model {'l2': [0.7918998906260053, 0.775975975975976]}\n",
      "step 290 model {'l2': [0.774807416111764, 0.8175213675213675]}\n",
      "step 300 model {'l2': [0.7948878205128205, 0.7820037105751392]}\n",
      "step 310 model {'l2': [0.7665170085862227, 0.8103741496598639]}\n",
      "step 320 model {'l2': [0.7960266614896784, 0.731195335276968]}\n",
      "step 330 model {'l2': [0.7857754081095314, 0.7792538157150932]}\n",
      "step 340 model {'l2': [0.7866110140425808, 0.7650145772594752]}\n",
      "step 350 model {'l2': [0.8073890662670229, 0.7231275014293883]}\n",
      "step 360 model {'l2': [0.7968495471427642, 0.759576901086335]}\n",
      "step 370 model {'l2': [0.7841271909819508, 0.7910234419668382]}\n",
      "step 380 model {'l2': [0.7784777411643082, 0.7774354460093896]}\n",
      "step 390 model {'l2': [0.7738373983739837, 0.8158725602755453]}\n",
      "step 400 model {'l2': [0.7882638308809355, 0.7909090909090909]}\n",
      "step 410 model {'l2': [0.7760063319764813, 0.8013497652582161]}\n",
      "step 420 model {'l2': [0.8033495934959349, 0.7210103329506314]}\n",
      "step 430 model {'l2': [0.7575369458128078, 0.8514431239388794]}\n",
      "step 440 model {'l2': [0.7884067818546562, 0.7565597667638484]}\n",
      "step 450 model {'l2': [0.8008653098262899, 0.7434782608695651]}\n",
      "step 460 model {'l2': [0.7741856197155403, 0.8115079365079365]}\n",
      "step 470 model {'l2': [0.7803694325412285, 0.802479815455594]}\n",
      "step 480 model {'l2': [0.782467741935484, 0.7928486997635934]}\n",
      "step 490 model {'l2': [0.8132696944028148, 0.6835334476843911]}\n",
      "step 500 model {'l2': [0.7787419354838709, 0.7804373522458629]}\n",
      "step 510 model {'l2': [0.7653368278004272, 0.8177842565597668]}\n",
      "step 520 model {'l2': [0.7780547034764828, 0.8182692307692307]}\n",
      "step 530 model {'l2': [0.7869296085040187, 0.7843478260869566]}\n",
      "step 540 model {'l2': [0.7862539246467819, 0.7953125]}\n",
      "step 550 model {'l2': [0.8048839771843401, 0.7362318840579709]}\n",
      "step 560 model {'l2': [0.7690400570391495, 0.8320289855072465]}\n",
      "step 570 model {'l2': [0.800492848859683, 0.7157534246575342]}\n",
      "step 580 model {'l2': [0.7862937381898744, 0.7680102915951973]}\n",
      "step 590 model {'l2': [0.7957471264367816, 0.7512733446519525]}\n",
      "step 600 model {'l2': [0.8129113181729328, 0.6995425957690109]}\n",
      "step 610 model {'l2': [0.7959730212259473, 0.7370056497175141]}\n",
      "step 620 model {'l2': [0.8114692897026361, 0.6776239907727797]}\n",
      "step 630 model {'l2': [0.7933673469387756, 0.7630681818181818]}\n",
      "step 640 model {'l2': [0.7946532917802883, 0.7292387543252594]}\n",
      "step 650 model {'l2': [0.8058400311122634, 0.7101449275362318]}\n",
      "step 660 model {'l2': [0.7787736776561579, 0.8064058956916099]}\n",
      "step 670 model {'l2': [0.7946612903225807, 0.759160756501182]}\n",
      "step 680 model {'l2': [0.7699354838709678, 0.8388002364066194]}\n",
      "step 690 model {'l2': [0.7605322580645161, 0.8108747044917258]}\n",
      "step 700 model {'l2': [0.775238371343899, 0.8016676593210242]}\n",
      "step 710 model {'l2': [0.7832621497443862, 0.7969387755102042]}\n",
      "step 720 model {'l2': [0.828965249466123, 0.6349854227405248]}\n",
      "step 730 model {'l2': [0.7905062445735658, 0.7806818181818183]}\n",
      "step 740 model {'l2': [0.7791544715447154, 0.799081515499426]}\n",
      "step 750 model {'l2': [0.7615177022424983, 0.8527272727272728]}\n",
      "step 760 model {'l2': [0.7953234379051075, 0.7684057971014493]}\n",
      "step 770 model {'l2': [0.7993767043241138, 0.7468281430219147]}\n",
      "step 780 model {'l2': [0.806705005461672, 0.7349999999999999]}\n",
      "step 790 model {'l2': [0.798591005597375, 0.7387387387387389]}\n",
      "step 800 model {'l2': [0.7775166470818645, 0.8096866096866097]}\n",
      "step 810 model {'l2': [0.7975337199452662, 0.7441395082904517]}\n",
      "step 820 model {'l2': [0.792807881773399, 0.7481607243916242]}\n",
      "step 830 model {'l2': [0.7839680146817856, 0.7456065759637188]}\n",
      "step 840 model {'l2': [0.7978643380429095, 0.7204545454545455]}\n",
      "step 850 model {'l2': [0.7857142857142858, 0.7815340909090909]}\n",
      "step 860 model {'l2': [0.773700899501715, 0.8064139941690962]}\n",
      "step 870 model {'l2': [0.805159450350013, 0.7318840579710145]}\n",
      "step 880 model {'l2': [0.7785514868198935, 0.801038062283737]}\n",
      "step 890 model {'l2': [0.787355186940495, 0.7645562464669304]}\n",
      "step 900 model {'l2': [0.7933287256450763, 0.778688524590164]}\n",
      "step 910 model {'l2': [0.7902025496667313, 0.758600583090379]}\n",
      "step 920 model {'l2': [0.8050081300813008, 0.699483352468427]}\n",
      "step 930 model {'l2': [0.8078861788617886, 0.6768082663605052]}\n",
      "step 940 model {'l2': [0.8018373983739836, 0.7319173363949484]}\n",
      "step 950 model {'l2': [0.7935303776683087, 0.740945104697227]}\n",
      "step 960 model {'l2': [0.8036311201415743, 0.7397959183673469]}\n",
      "step 970 model {'l2': [0.7933476955216086, 0.7396011396011396]}\n",
      "step 980 model {'l2': [0.790089268260898, 0.7435677530017153]}\n",
      "step 990 model {'l2': [0.7891382113821139, 0.7591848450057406]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../data/fitting_data.csv')\n",
    "df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "df = df.fillna(0)\n",
    "y = df.pop('music').values\n",
    "stratification_columns = df.pop('stratification_column').values\n",
    "X = df.values\n",
    "\n",
    "\n",
    "models_iterate = {}\n",
    "scores_iterate = {}\n",
    "for i in range(1000):\n",
    "    models_iterate[i], scores_iterate[i] = model_fitting(X,y,logit_num,model_names,pipelines,hyperparameters,datapointers,i+12000,stratification_columns)\n",
    "    if i%10 == 0:\n",
    "        print('step',i,'model',scores_iterate[i])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('../data/pp_1000_models.pkl', 'wb') as picklefile:\n",
    "    pkl.dump(models_iterate, picklefile)\n",
    "with open('../data/pp_1000_models_scores.pkl', 'wb') as picklefile:\n",
    "    pkl.dump(scores_iterate, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
