{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data cleaning finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert anonymized data for further processing\n",
    "Input: anonymized data\n",
    "Output: filtered features matrix for modeling,\n",
    "        unfiltered features matrix for exploring\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import re\n",
    "\n",
    "\n",
    "# read in data\n",
    "df = pd.read_csv('../data/CYSOanonymized.csv')\n",
    "\n",
    "# set financial aid status to 0 if NaN\n",
    "\n",
    "df['finaid'].fillna(0,inplace=True)\n",
    "\n",
    "# parse race into different rows\n",
    "df['race'].fillna('Other',inplace=True)\n",
    "df['caucasian']=0\n",
    "df['african_american']=0\n",
    "df['native_american']=0\n",
    "df['latino']=0\n",
    "df['asian']=0\n",
    "df['other_race']=0\n",
    "df['race_num']=0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if re.search('cauc', str(row['race']), re.IGNORECASE):\n",
    "        df.loc[index,'caucasian']=1\n",
    "        df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "    if re.search('african', str(row['race']), re.IGNORECASE):\n",
    "        df.loc[index,'african_american']=1\n",
    "        df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "    if re.search('native', str(row['race']), re.IGNORECASE):\n",
    "        df.loc[index,'caucasian']=1\n",
    "        df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "    if re.search('latino', str(row['race']), re.IGNORECASE):\n",
    "        df.loc[index,'latino']=1\n",
    "        df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "    if re.search('asian', str(row['race']), re.IGNORECASE):\n",
    "        if not re.search('caucasian', str(row['race']), re.IGNORECASE):\n",
    "            df.loc[index,'asian']=1\n",
    "            df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "    if re.search('other', str(row['race']), re.IGNORECASE):\n",
    "        df.loc[index,'other_race']=1\n",
    "        df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "    if re.search(\"`\", str(row['race']), re.IGNORECASE):\n",
    "        df.loc[index,'other_race']=1\n",
    "        df.loc[index,'race_num']=df.loc[index,'race_num']+1\n",
    "\n",
    "# compile gender\n",
    "df['male']=0\n",
    "df['female']=0\n",
    "\n",
    "df.gender = df.gender.str.strip()\n",
    "df.gender.replace('Male','M',inplace=True)\n",
    "df.gender.replace('Female','F',inplace=True)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['gender']=='M':\n",
    "        df.loc[index, 'male']=1\n",
    "    if row['gender']=='F':\n",
    "        df.loc[index,'female']=1\n",
    "\n",
    "# compile major\n",
    "\n",
    "df['music']=0\n",
    "\n",
    "music_terms = ['performance','music','violin','songwriting','perfomance','bass','cello','viola','jazz']\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for music_term in music_terms:\n",
    "        if re.search(music_term,str(row['major']),re.IGNORECASE):\n",
    "            df.loc[index,'music']=1\n",
    "    \n",
    "\n",
    "'''\n",
    "map in and combine incomes\n",
    "'''\n",
    "#read in incomes and convert to numeric\n",
    "income = pd.read_csv('../data/income_zip.csv')\n",
    "df['homezip']=pd.to_numeric(df['homezip'], errors='coerce')\n",
    "\n",
    "# merge with data structure\n",
    "df = pd.merge(df,income,how='left',left_on='homezip',right_on='Zip')\n",
    "\n",
    "\n",
    "# rename and reformat columns\n",
    "df.rename(index=str, columns={\"Mean\": \"mean_income\", \"Median\": \"median_income\", \\\n",
    "                              \"finaid\" : \"financial_aid\", \"race_num\" : \"multiracial\"}, inplace=True)\n",
    "df['mean_income'] = df['median_income'].str.replace(',','')\n",
    "df['mean_income']=pd.to_numeric(df['mean_income'], errors='coerce')\n",
    "df['median_income'] = df['median_income'].str.replace(',','')\n",
    "df['median_income']=pd.to_numeric(df['median_income'], errors='coerce')\n",
    "df['income_diff']=df['mean_income']-df['median_income']\n",
    "\n",
    "'''\n",
    "map in and combine college data\n",
    "'''\n",
    "\n",
    "# read in college data\n",
    "uf = pd.read_csv('../data/colleges.csv')\n",
    "\n",
    "# filter to relevant universal columns\n",
    "uf = uf[['displayName','acceptance-rate','institutionalControl']]\n",
    "\n",
    "# build columns for merging and saving\n",
    "df['uni_close'] = 'none'\n",
    "df['uni_save'] = df['uni']\n",
    "\n",
    "# replace strings\n",
    "\n",
    "# strip name function\n",
    "def stripnames(dataframe,instring,outstring):\n",
    "    dataframe.loc[df['uni'].str.replace(' ','').replace(\"'\",'').replace('-','') \\\n",
    "                  ==instring.replace(' ','').replace(\"'\",'').replace('-',''),'uni']=outstring\n",
    "    return dataframe\n",
    "\n",
    "# strip and modify names for matching\n",
    "uf['displayName'] = uf['displayName'].fillna('none')\n",
    "df['uni'] = df['uni'].fillna('none given')\n",
    "df['uni'] = df['uni'].str.replace('Uof','University of')\n",
    "df['uni'] = df['uni'].str.replace('U of','University of')\n",
    "df['uni'] = df['uni'].str.replace('Jacobs School of Music','')\n",
    "df = stripnames(df,'Indiana University','Indiana University--Bloomington')\n",
    "df = stripnames(df,'NYU','New York University')\n",
    "df = stripnames(df,'Oberlin','Oberlin College')\n",
    "df = stripnames(df,'UIC','University of Illinois Chicago')\n",
    "df = stripnames(df,'UIUC','University of Illinois--Urbana Champaign')\n",
    "df = stripnames(df,'USC(So.Cal.)','University of Southern California')\n",
    "df = stripnames(df,'UofMichigan','University of Michigan')\n",
    "df = stripnames(df,'Peabody','Johns Hopkins University')\n",
    "df = stripnames(df,'University of I','University of Illinois--Urbana Champaign')\n",
    "df = stripnames(df,'NIU','Northern Illinois University')\n",
    "df = stripnames(df,'U.ofMinnesotaCarlsonSchoolofBusiness','University of Minnesota')\n",
    "df = stripnames(df,'NEC','New England Conservatory')\n",
    "df = stripnames(df,'MIT','Massachussetts Institute of Technology')\n",
    "df = stripnames(df,'Gap Year','none')\n",
    "df = stripnames(df,'Year off','none')\n",
    "df = stripnames(df,'The Juilliard School','Julliard School')\n",
    "df = stripnames(df,'IUBloomington,JacobsSchoolofMusic','Indiana University--Bloomington')\n",
    "df = stripnames(df,'IUJacobsSchoolofMusic','Indiana University--Bloomington')\n",
    "df = stripnames(df,'HarvardCollege','Harvard University')\n",
    "df = stripnames(df,'Undecided','none')\n",
    "df = stripnames(df,'NotgoingtoCollege','none')\n",
    "df = stripnames(df,'IndianaUniversityJacobsSchoolofMusic','Indiana University--Bloomington')\n",
    "df = stripnames(df,'IndianaUniversity,JacobsSchoolofMusic','Indiana University--Bloomington')\n",
    "df = stripnames(df,'IndianaUniversity(JacobsSchoolofMusic)','Indiana University--Bloomington')\n",
    "df = stripnames(df,'JacobsSchoolofMusic,atIndianaUniversity','Indiana University--Bloomington')\n",
    "df = stripnames(df,'ClarendonHillsMiddleSchool','none')\n",
    "df = stripnames(df,'IU','Indiana University--Bloomington')\n",
    "df = stripnames(df,'LawrenceConservatory','Lawrence University')\n",
    "df = stripnames(df,'IndianaUniversity','Indiana University--Bloomington')\n",
    "df = stripnames(df,'WesternIllinoisUniversity','WesternIllinois')\n",
    "df = stripnames(df,'UniversityofIllinois','University of Illinois--Urbana Champaign')\n",
    "df = stripnames(df,',atIndianaUniversity','Indiana University--Bloomington')\n",
    "\n",
    "# match name to closest\n",
    "for index, row in df.iterrows():\n",
    "    df.loc[index, 'uni_close']=process.extractOne(row['uni'],uf['displayName'])[0]\n",
    "\n",
    "\n",
    "# merge university data into full data structure\n",
    "df = pd.merge(df,uf,how='left',left_on='uni_close',right_on='displayName')\n",
    "\n",
    "# encode university types\n",
    "df['uni_public'] = 0\n",
    "# df.loc(df['institutionalControl']=='private','institutionalControl')=0\n",
    "# df.loc(df['institutionalControl']=='none','institutionalControl')=0\n",
    "df.loc[df['institutionalControl']=='public','uni_public']=1\n",
    "\n",
    "# drop spurious columns and rename others\n",
    "df.drop(['Unnamed: 0','Zip','institutionalControl','displayName','uni_save','uni'],axis=1, inplace=True)\n",
    "df.rename(index=str, columns={\"uni_close\": \"uni\",\"acceptance-rate\":\"acceptance_rate\"}, inplace=True)\n",
    "\n",
    "# force non numerics to numerics\n",
    "df['acceptance_rate']=pd.to_numeric(df['acceptance_rate'], errors='coerce')\n",
    "\n",
    "\"\"\"\n",
    "Use zip codes to determine if in city of chicago\n",
    "\"\"\"\n",
    "\n",
    "# read in city of chicago zipcodes\n",
    "zipcodes = pd.read_csv('../data/chicago_zipcodes.csv')\n",
    "\n",
    "# convert to integers\n",
    "df['s_zip']=pd.to_numeric(df['s_zip'], errors='coerce')\n",
    "df.s_zip = df.s_zip.fillna(0)\n",
    "df.s_zip = df.s_zip.astype(int)\n",
    "df['homezip']=pd.to_numeric(df['homezip'], errors='coerce')\n",
    "df.homezip = df.homezip.fillna(0)\n",
    "df.homezip = df.homezip.astype(int)\n",
    "zipcodes['ZIP']=pd.to_numeric(zipcodes['ZIP'], errors='coerce',downcast='integer')\n",
    "zipcodes.ZIP = zipcodes.ZIP.astype(int)\n",
    "\n",
    "# column for in chicago\n",
    "df['chi_school']=0\n",
    "df['notchi_school']=0\n",
    "df['chi_home']=0\n",
    "df['notchi_home']=0\n",
    "\n",
    "df.loc[df['s_zip'].isin(zipcodes['ZIP']),'chi_school']=1\n",
    "df.loc[~df['s_zip'].isin(zipcodes['ZIP']),'notchi_school']=1\n",
    "df.loc[df['homezip'].isin(zipcodes['ZIP']),'chi_home']=1\n",
    "df.loc[~df['homezip'].isin(zipcodes['ZIP']),'notchi_home']=1\n",
    "\n",
    "\"\"\"\n",
    "make seperate column for stratification?\n",
    "\"\"\"\n",
    "\n",
    "df['stratification_column'] = 0\n",
    "df.loc[df['african_american']==1,'stratification_column']=1\n",
    "df.loc[df['latino']==1,'stratification_column']=1\n",
    "\n",
    "# save full data structure\n",
    "df.to_csv('../data/exploring_data.csv')\n",
    "\n",
    "# # drop all data not used in modeling - comment in when prepping data\n",
    "# df.drop(['Zip', 'Pop', 'Unnamed: 0','instrument','race','gender','s_ensemble',\\\n",
    "#         'm_employ','m_job','d_employ','school','s_address','uni','pt',\\\n",
    "#         's_state','major','homezip','s_zip','studentID','mean_income',\n",
    "#         'gradyear','female','native_american','income_diff'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# # for fitting data with causal characteristics only\n",
    "# df = df[['female','other_race','chi_school','chi_home','music','male','caucasian','african_american',\n",
    "#          'latino', 'asian','notchi_school','notchi_home','financial_aid',\n",
    "#          'median_income']]\n",
    "\n",
    "# for fitting data including likely correlated features\n",
    "df_fit = df[['female','other_race','notchi_school','notchi_home','uni_public',\n",
    "         'acceptance_rate','stratification_column','music','male','caucasian','african_american',\n",
    "         'latino', 'asian','chi_school','chi_home','financial_aid',\n",
    "         'median_income']]\n",
    "\n",
    "# # for logistic regression classifiers\n",
    "# df = df[['music','male','caucasian','african_american',\n",
    "#          'latino', 'asian','multiracial','financial_aid',\n",
    "#          'median_income','acceptance_rate','uni_public']]\n",
    "\n",
    "# save fitting data structure\n",
    "df_fit.to_csv('../data/fitting_data.csv')\n",
    "\n",
    "# for mapping in tableau\n",
    "df_map = df[['female','male','music','caucasian','african_american',\n",
    "             'latino','asian','other_race','s_zip','financial_aid']]\n",
    "\n",
    "# save fitting data structure\n",
    "df_map.to_csv('../data/mapping_data.csv')\n",
    "\n",
    "print('data cleaning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stratification_column.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['chi_school'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['acceptance-rate'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'s_zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 's_zip'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-9be75e9886aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's_zip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 's_zip'"
     ]
    }
   ],
   "source": [
    "df['s_zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
